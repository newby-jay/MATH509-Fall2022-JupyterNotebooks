{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from ipywidgets import interact\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "# import pymc3 as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "import warnings # the warning spam is pointless and annoying\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this assigment, use the code provided in the cells below together with the lecture code in the Week 11 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Sampling from a biomodal target distribution\n",
    "Use the MCMC samplers in the Tensorflow Probability package, specifically the Hamiltonian Monte Carlo and No U Turn Sampler, to sample from a multipmodel density in two dimensions. Throughout this problem, our target distribution will be the sum of two Gaussian densities. The terget density has two modes or peaks in the top left and bottom right corner, with the origin in between them. \n",
    "\n",
    "Throughout this problem, use the initial condition (code provided below) for all chains, $(x_0, y_0) = (-2, 2)$\n",
    "\n",
    "\n",
    "\n",
    "## A\n",
    "Using `sigma=2.0` in the target distribution, sample 4 parallel chains each with 1000 steps. Use 100 burnin steps. To sample the target density, you will use one of the following MCMC algorithms,\n",
    "  * `NoUTurnSampler`\n",
    "  * `HamiltonianMonteCarlo`\n",
    "  \n",
    "and one step size adapter,\n",
    "  * `SimpleStepSizeAdaptation`\n",
    "  * `DualAveragingStepSizeAdaptation`\n",
    " \n",
    "\n",
    "That gives four possible combinations of algorithm + step size adapter. For each combination compute the following\n",
    "  1. plot the combined sample set along side the target density (e.g., with `pcolor` or `contourf`)\n",
    "  2. print the mean of the sampled 2D positions (the exact mean is at the origin)\n",
    "  3. print the acceptance ratio for each independent chain\n",
    "  4. print the effective sample size for each independent chain (use `effective_sample_size`)\n",
    "  \n",
    "Finally, write what you think the best combination is and explain why.\n",
    "\n",
    "## B\n",
    "Repeat part A with `sigma=1.0`.\n",
    "\n",
    "## C\n",
    "Repeat part A with `sigma=0.5`.\n",
    "\n",
    "## D\n",
    "Does a large effective sample size always indicate an accurate estimate of the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-3.7815107311260943, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def make_target_log_density(sigma=None):\n",
    "    G1 = tfd.MultivariateNormalDiag(loc=[-2., 2.], scale_diag=sigma*ones([2]))\n",
    "    G2 = tfd.MultivariateNormalDiag(loc=[2., -2.], scale_diag=sigma*ones([2]))\n",
    "    def target_log_density(x):\n",
    "        return tf.math.log(G1.prob(x) + G2.prob(x))\n",
    "    return target_log_density\n",
    "\n",
    "target_L_part_A = make_target_log_density(sigma=2.0)\n",
    "xtest = normal(0, 1, 2)\n",
    "print(target_L_part_A(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nchains = 4\n",
    "\n",
    "Xinit = ones((Nchains, 2))\n",
    "Xinit[:, 0] = -2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
